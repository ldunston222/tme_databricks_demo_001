{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab18814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "try:\n",
    "    spark\n",
    "except NameError as e:\n",
    "    raise RuntimeError('This notebook must be run on a Spark cluster (Databricks) with an active `spark` session.') from e\n",
    "\n",
    "now = datetime.now(timezone.utc)\n",
    "episode_id = str(uuid.uuid4())\n",
    "episode_version = 1\n",
    "evaluation_id = str(uuid.uuid4())\n",
    "print('episode_id:', episode_id)\n",
    "print('evaluation_id:', evaluation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b578f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_row = {\n",
    "    'episode_id': episode_id,\n",
    "    'episode_version': episode_version,\n",
    "    'created_at': now,\n",
    "    'status': 'completed',\n",
    "    'source': 'seed_notebook',\n",
    "    'source_ref': None,\n",
    "    'inputs_json': json.dumps({'query': 'What is the capital of France?'}),\n",
    "    'expected_outputs_json': json.dumps({'answer': 'Paris'}),\n",
    "    'actual_outputs_json': json.dumps({'answer': 'Paris'}),\n",
    "    'metadata_json': json.dumps({'note': 'minimal seed'}),\n",
    "    'input_tokens': 12,\n",
    "    'output_tokens': 3,\n",
    "    'total_tokens': 15,\n",
    "}\n",
    "\n",
    "steps_rows = [\n",
    "    {\n",
    "        'episode_id': episode_id,\n",
    "        'episode_version': episode_version,\n",
    "        'step_index': 0,\n",
    "        'step_type': 'user',\n",
    "        'content': 'What is the capital of France?',\n",
    "        'created_at': now,\n",
    "        'metadata_json': None,\n",
    "    },\n",
    "    {\n",
    "        'episode_id': episode_id,\n",
    "        'episode_version': episode_version,\n",
    "        'step_index': 1,\n",
    "        'step_type': 'assistant',\n",
    "        'content': 'Paris.',\n",
    "        'created_at': now,\n",
    "        'metadata_json': None,\n",
    "    },\n",
    "]\n",
    "\n",
    "evaluation_row = {\n",
    "    'evaluation_id': evaluation_id,\n",
    "    'episode_id': episode_id,\n",
    "    'episode_version': episode_version,\n",
    "    'evaluated_at': now,\n",
    "    'evaluator_name': 'ai_workflow_evaluator',\n",
    "    'evaluator_version': 'dev',\n",
    "    'mlflow_run_id': None,\n",
    "    'match_outcome': 'match',\n",
    "    'overall_score': 1.0,\n",
    "    'drift_score': 0.0,\n",
    "    'coherence_score': 1.0,\n",
    "    'idempotency_score': 1.0,\n",
    "    'metrics_json': json.dumps({'seed': True}),\n",
    "}\n",
    "\n",
    "spark.createDataFrame([episode_row]).write.mode('append').saveAsTable('datamodel_db.episode')\n",
    "spark.createDataFrame(steps_rows).write.mode('append').saveAsTable('datamodel_db.episode_steps')\n",
    "spark.createDataFrame([evaluation_row]).write.mode('append').saveAsTable('datamodel_db.episode_evaluation')\n",
    "\n",
    "print('âœ“ Seeded one episode, two steps, one evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM datamodel_db.episode ORDER BY created_at DESC LIMIT 5').show(truncate=False)\n",
    "spark.sql('SELECT * FROM datamodel_db.episode_steps WHERE episode_id = %s ORDER BY step_index' % episode_id).show(truncate=False)\n",
    "spark.sql('SELECT * FROM datamodel_db.episode_evaluation WHERE episode_id = %s ORDER BY evaluated_at DESC' % episode_id).show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
