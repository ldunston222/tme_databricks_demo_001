{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6abdba7e",
      "metadata": {
        "id": "6abdba7e"
      },
      "outputs": [],
      "source": [
        "ddl_statements = [\n",
        "    \"\"\"CREATE SCHEMA IF NOT EXISTS datamodel_db\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS datamodel_db.episode (\n",
        "  episode_id STRING NOT NULL,\n",
        "  episode_version INT NOT NULL,\n",
        "  created_at TIMESTAMP,\n",
        "  started_at TIMESTAMP,\n",
        "  ended_at TIMESTAMP,\n",
        "  duration_ms BIGINT,\n",
        "  status STRING NOT NULL,\n",
        "  workflow_name STRING,\n",
        "  model_name STRING,\n",
        "  model_version STRING,\n",
        "  agent_version STRING,\n",
        "  is_golden BOOLEAN,\n",
        "  golden_template_id STRING,\n",
        "  source STRING,\n",
        "  source_ref STRING,\n",
        "  inputs_json STRING,\n",
        "  expected_outputs_json STRING,\n",
        "  actual_outputs_json STRING,\n",
        "  metadata_json STRING,\n",
        "  cost_usd DOUBLE,\n",
        "  cost_input_usd DOUBLE,\n",
        "  cost_output_usd DOUBLE,\n",
        "  input_tokens BIGINT,\n",
        "  output_tokens BIGINT,\n",
        "  total_tokens BIGINT,\n",
        "  CONSTRAINT episode_status_check CHECK (status IN ('successful', 'degraded', 'failed'))\n",
        ")\n",
        "USING DELTA\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS datamodel_db.episode_steps (\n",
        "  episode_id STRING NOT NULL,\n",
        "  episode_version INT NOT NULL,\n",
        "  step_index INT NOT NULL,\n",
        "  step_type STRING,\n",
        "  step_name STRING,\n",
        "  content STRING,\n",
        "  created_at TIMESTAMP,\n",
        "  tokens_in BIGINT,\n",
        "  tokens_out BIGINT,\n",
        "  total_tokens BIGINT,\n",
        "  latency_ms BIGINT,\n",
        "  score DOUBLE,\n",
        "  failure_type STRING,\n",
        "  invariant_violated STRING,\n",
        "  metadata_json STRING,\n",
        "  CONSTRAINT step_index_nonnegative CHECK (step_index >= 0)\n",
        ")\n",
        "USING DELTA\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS datamodel_db.episode_evaluation (\n",
        "  evaluation_id STRING NOT NULL,\n",
        "  episode_id STRING NOT NULL,\n",
        "  episode_version INT NOT NULL,\n",
        "  evaluated_at TIMESTAMP,\n",
        "  evaluator_name STRING,\n",
        "  evaluator_version STRING,\n",
        "  mlflow_run_id STRING,\n",
        "  match_outcome STRING,\n",
        "  overall_score DOUBLE,\n",
        "  drift_score DOUBLE,\n",
        "  coherence_score DOUBLE,\n",
        "  idempotency_score DOUBLE,\n",
        "  artifact_uri STRING,\n",
        "  metrics_json STRING,\n",
        "  CONSTRAINT match_outcome_check CHECK (match_outcome IN ('match', 'mismatch', 'undetermined'))\n",
        ")\n",
        "USING DELTA\n",
        "\"\"\",\n",
        "]\n",
        "\n",
        "try:\n",
        "    spark\n",
        "except NameError as e:\n",
        "    raise RuntimeError('This notebook must be run on a Spark cluster (Databricks) with an active `spark` session.') from e\n",
        "\n",
        "for stmt in ddl_statements:\n",
        "    spark.sql(stmt)\n",
        "\n",
        "# If tables already existed, ensure new columns are present.\n",
        "# (CREATE TABLE IF NOT EXISTS will not evolve schemas automatically.)\n",
        "\n",
        "def _add_columns_if_missing(table_name: str, columns_ddl: list[tuple[str, str]]):\n",
        "    existing = {r.col_name for r in spark.sql(f\"DESCRIBE {table_name}\").collect() if r.col_name and not r.col_name.startswith('#')}\n",
        "    to_add = [(name, dtype) for (name, dtype) in columns_ddl if name not in existing]\n",
        "    if to_add:\n",
        "        cols_sql = \", \".join([f\"{name} {dtype}\" for name, dtype in to_add])\n",
        "        spark.sql(f\"ALTER TABLE {table_name} ADD COLUMNS ({cols_sql})\")\n",
        "\n",
        "_add_columns_if_missing(\n",
        "    \"datamodel_db.episode\",\n",
        "    [\n",
        "        (\"started_at\", \"TIMESTAMP\"),\n",
        "        (\"ended_at\", \"TIMESTAMP\"),\n",
        "        (\"duration_ms\", \"BIGINT\"),\n",
        "        (\"workflow_name\", \"STRING\"),\n",
        "        (\"model_name\", \"STRING\"),\n",
        "        (\"model_version\", \"STRING\"),\n",
        "        (\"agent_version\", \"STRING\"),\n",
        "        (\"is_golden\", \"BOOLEAN\"),\n",
        "        (\"golden_template_id\", \"STRING\"),\n",
        "        (\"cost_usd\", \"DOUBLE\"),\n",
        "        (\"cost_input_usd\", \"DOUBLE\"),\n",
        "        (\"cost_output_usd\", \"DOUBLE\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "_add_columns_if_missing(\n",
        "    \"datamodel_db.episode_steps\",\n",
        "    [\n",
        "        (\"step_name\", \"STRING\"),\n",
        "        (\"tokens_in\", \"BIGINT\"),\n",
        "        (\"tokens_out\", \"BIGINT\"),\n",
        "        (\"total_tokens\", \"BIGINT\"),\n",
        "        (\"latency_ms\", \"BIGINT\"),\n",
        "        (\"score\", \"DOUBLE\"),\n",
        "        (\"failure_type\", \"STRING\"),\n",
        "        (\"invariant_violated\", \"STRING\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "_add_columns_if_missing(\n",
        "    \"datamodel_db.episode_evaluation\",\n",
        "    [\n",
        "        (\"artifact_uri\", \"STRING\"),\n",
        "    ],\n",
        ")\n",
        "\n",
        "print('âœ“ Created/updated schema and tables in datamodel_db')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd0dd0db",
      "metadata": {
        "id": "fd0dd0db"
      },
      "outputs": [],
      "source": [
        "spark.sql('SHOW TABLES IN datamodel_db').show(truncate=False)\n",
        "spark.sql('DESCRIBE TABLE datamodel_db.episode').show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
